{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hackathon.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypu4DrNXTRT8"
      },
      "source": [
        "import os, from __future__ import print_function, division, import cv2\n",
        "import numpy as np, from tqdm import tqdm\n",
        "import torch, import torch.nn.functional as F, import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, from torchvision.transforms import transforms, from torch.utils.data import DataLoader, from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "mutated_data = pd.read_csv('mutated_data - Sheet1.csv').sample(frac=1)\n",
        "load_data = mutated_data.drop('Disease class (1=healthy, 2=cf, 3=gt, 4=bs, 5=sc)', axis=1)\n",
        "\n",
        "\n",
        "load_data = (load_data-load_data.min())/(load_data.max()-load_data.min()) ##normalized data\n",
        "load_data = torch.tensor(pd.DataFrame(data=load_data).values)\n",
        "\n",
        "load_labels = mutated_data.iloc[:, -1] #labels of disease\n",
        "\n",
        "labels = []\n",
        "\n",
        "for item in load_labels: \n",
        "  disc_class = [0, 0, 0, 0, 0]\n",
        "  index = 0\n",
        "  disc_class[int(item)-1] = 1\n",
        "  labels.append(disc_class)\n",
        "  index += 1\n",
        "\n",
        "load_labels = torch.FloatTensor(labels)\n",
        "train_data = []\n",
        "\n",
        "for i in range(len(load_data)):\n",
        "   train_data.append([load_data[i], load_labels[i]])\n",
        "\n",
        "training = train_data[0:int(len(train_data) * .80)]\n",
        "testing = train_data[(int(len(train_data) * .80)): (int(len(train_data) * 1))]\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(training, shuffle=True, batch_size=50)\n",
        "testloader = torch.utils.data.DataLoader(testing, shuffle=True, batch_size=50)\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(26, 64)\n",
        "        self.fc2 = nn.Linear(64, 64)\n",
        "        self.fc3 = nn.Linear(64, 64)\n",
        "        self.fc4 = nn.Linear(64, 5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "        \n",
        "        return x\n",
        "    \n",
        "net = Net()\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for data in trainloader:\n",
        "        X, y = data\n",
        "        net.zero_grad()\n",
        "        output = net(X.float())\n",
        "        y.view(-1, 5)\n",
        "    #     loss = F.nll_loss(output, F.log_softmax(y))\n",
        "    #     loss.backward()\n",
        "    #     optimizer.step()\n",
        "    # print(loss)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNig9Xfql7-e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}